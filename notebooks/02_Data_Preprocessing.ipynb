{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2830f0e6-0d03-4137-bf76-c47121fda38f",
   "metadata": {},
   "source": [
    "# Multi-Feature Banking Adoption and Customer Churn Prediction\n",
    "## Step 2: Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b647cd-096f-440b-ada9-20a697720d31",
   "metadata": {},
   "source": [
    "**Goal:** Prepare a clean dataset ready for exploratory data analysis and modeling.\n",
    "\n",
    "Based on the issues identified in Step 1, we will perform the following data cleaning tasks:\n",
    "\n",
    "**Tasks to Complete:**\n",
    "1. Handle missing values in Surname and Age\n",
    "2. Remove duplicate Tenure column\n",
    "3. Convert Balance and EstimatedSalary from text to numeric\n",
    "4. Convert HasCrCard and IsActiveMember from Yes/No to binary (1/0)\n",
    "5. Standardize Geography values (FRA/France/French → consistent format)\n",
    "6. Verify all data type conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a3a2d7f-911e-47fd-bc56-d224bc0fc074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "#Importing pandas libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Display setting for pandas\n",
    "pd.set_option('display.max_columns', None)              #show all columns\n",
    "pd.set_option('display.float_format','{:.2f}'.format)    #format all decimals to 2 places\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f6abf52-b9e5-487d-8949-08402f5428a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "======================================================================\n",
      "Dataset Shape: 10,001 rows × 14 columns\n"
     ]
    }
   ],
   "source": [
    "#Load the dataset\n",
    "df = pd.read_csv('../data/Bank_Churn_Messy.csv', encoding='latin-1')\n",
    "\n",
    "# Display dataset dimensions\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Dataset Shape: {df.shape[0]:,} rows × {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec9af49-3590-4ef0-a31b-0d032093ca33",
   "metadata": {},
   "source": [
    "### 2.1 Handling Missing Values\n",
    "\n",
    "We identified 6 missing values:\n",
    "- Surname: 3 missing\n",
    "- Age: 3 missing\n",
    "\n",
    "**Strategy:**\n",
    "- Since missing values represent only 0.03% of the data (3 out of 10,001 rows)\n",
    "- Age is an important feature for churn analysis\n",
    "- We will **`remove the 3 rows`** with missing values rather than imputing, as:\n",
    "  - The loss of 3 rows is negligible\n",
    "  - Imputing age could introduce bias\n",
    "  - Surname is not useful for analysis anyway\n",
    "\n",
    "First, we need to verify these are the same 3 rows with both missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1839139f-a396-44c0-a0b4-4b2f2445f9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with missing values:\n",
      "Total rows with missing values: 3\n",
      "\n",
      "Details of rows with missing data:\n",
      "      CustomerId Surname  Age Geography  Gender  Exited\n",
      "28      15728693     NaN  NaN   Germany  Female       0\n",
      "121     15580203     NaN  NaN     Spain    Male       0\n",
      "9389    15756954     NaN  NaN    France  Female       0\n"
     ]
    }
   ],
   "source": [
    "# Identify rows with missing values\n",
    "print(\"Rows with missing values:\")\n",
    "\n",
    "# Find rows where either Surname or Age is missing\n",
    "missing_rows = df[df['Surname'].isnull() | df['Age'].isnull()]\n",
    "print(f\"Total rows with missing values: {len(missing_rows)}\")\n",
    "print(\"\\nDetails of rows with missing data:\")\n",
    "print(missing_rows[['CustomerId', 'Surname', 'Age', 'Geography', 'Gender', 'Exited']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef6d2c64-0ec9-4c8d-a983-d8745d55d97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values Removal:\n",
      "Original dataset size: 10,001 rows\n",
      "Rows removed: 3\n",
      "New dataset size: 9,998 rows\n",
      "======================================================================\n",
      "\n",
      "Remaining missing values:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with missing values\n",
    "original_size = len(df)                         # Store original dataset size\n",
    "df = df.dropna(subset=['Surname', 'Age'])\n",
    "\n",
    "\n",
    "new_size = len(df)                              # Store new size\n",
    "\n",
    "# Displaying results\n",
    "print(\"Missing Values Removal:\")\n",
    "\n",
    "print(f\"Original dataset size: {original_size:,} rows\")\n",
    "print(f\"Rows removed: {original_size - new_size}\")\n",
    "print(f\"New dataset size: {new_size:,} rows\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Verifying no missing values remain\n",
    "print(f\"\\nRemaining missing values:\")\n",
    "print(df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f888f1f3-a461-450e-9aab-d411eb40e4fb",
   "metadata": {},
   "source": [
    "### 2.2 Removing Duplicate Column\n",
    "\n",
    "The dataset contains two identical Tenure columns:\n",
    "- Tenure (column 6)\n",
    "- Tenure.1 (column 10)\n",
    "\n",
    "Statistical analysis confirmed they have identical values. We will remove Tenure.1 (keeping the original Tenure column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6875493-c4ed-4950-a802-fc5e90f1a1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing Duplicate Column:\n",
      "Columns before removal: 14\n",
      "Columns after removal: 13\n",
      "\n",
      "Tenure.1 column removed successfully\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate Tenure column\n",
    "print(\"Removing Duplicate Column:\")\n",
    "\n",
    "print(f\"Columns before removal: {len(df.columns)}\")\n",
    "\n",
    "df = df.drop('Tenure.1', axis=1)                        # Remove Tenure.1\n",
    "\n",
    "print(f\"Columns after removal: {len(df.columns)}\")\n",
    "print(\"\\nTenure.1 column removed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdd58c2-da4d-4402-bc70-3cc32bec61c5",
   "metadata": {},
   "source": [
    "### 2.3 Converting Balance and EstimatedSalary to Numeric\n",
    "\n",
    "**Issue:** Balance and EstimatedSalary are stored as text (object) due to special characters (currency symbols).\n",
    "\n",
    "**Strategy:**\n",
    "- Remove all non-numeric characters (keeping only digits and decimal points)\n",
    "- Convert to float type\n",
    "- Verify conversion success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85db1f6d-c77d-4d66-8679-53262d48823b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Balance to numeric:\n",
      "Balance converted to numeric\n",
      "EstimatedSalary converted to numeric\n",
      "\n",
      "Verification:\n",
      "Balance data type: float64\n",
      "EstimatedSalary data type: float64\n"
     ]
    }
   ],
   "source": [
    "# Clean and convert Balance to numeric\n",
    "print(\"Converting Balance to numeric:\")\n",
    "\n",
    "# Use regex pattern to remove non-numeric characters\n",
    "# r'[^\\d.]' means: remove anything that is NOT a digit (\\d) or decimal point (.)\n",
    "# The ^ inside [] means \"NOT\" - so [^\\d.] = \"not digit or dot\"\n",
    "# This removes currency symbols like £, €, $ while keeping numbers intact\n",
    "df['Balance'] = df['Balance'].str.replace(r'[^\\d.]', '', regex=True).astype(float)\n",
    "print(\"Balance converted to numeric\")\n",
    "\n",
    "# Apply same regex cleaning to EstimatedSalary\n",
    "df['EstimatedSalary'] = df['EstimatedSalary'].str.replace(r'[^\\d.]', '', regex=True).astype(float)\n",
    "print(\"EstimatedSalary converted to numeric\")\n",
    "\n",
    "\n",
    "\n",
    "# Verifying successful conversion\n",
    "print(\"\\nVerification:\")\n",
    "print(f\"Balance data type: {df['Balance'].dtype}\")\n",
    "print(f\"EstimatedSalary data type: {df['EstimatedSalary'].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a388e6e9-3a58-4b35-8c51-73052332dfb1",
   "metadata": {},
   "source": [
    "### 2.4 Converting Binary Columns to Numeric\n",
    "\n",
    "**Issue:** HasCrCard and IsActiveMember are stored as \"Yes\"/\"No\" text instead of binary values.\n",
    "\n",
    "**Why convert to 1/0:**\n",
    "- Machine learning models require numeric input\n",
    "- Binary format (1/0) is standard for Yes/No data\n",
    "- Enables mathematical operations and correlations\n",
    "\n",
    "**Conversion:**\n",
    "- \"Yes\" → 1\n",
    "- \"No\" → 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5b432a2-78e0-46fa-aafd-7c0474f4cba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HasCrCard converted to binary (Yes → 1, No → 0)\n",
      "IsActiveMember converted to binary (Yes → 1, No → 0)\n",
      "======================================================================\n",
      "\n",
      "Verification:\n",
      "HasCrCard - Type: int64, Values: [1 0]\n",
      "IsActiveMember - Type: int64, Values: [1 0]\n"
     ]
    }
   ],
   "source": [
    "# Converting Yes → 1, No → 0\n",
    "df['HasCrCard'] = df['HasCrCard'].map({'Yes': 1, 'No': 0})\n",
    "df['IsActiveMember'] = df['IsActiveMember'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "print(\"HasCrCard converted to binary (Yes → 1, No → 0)\")\n",
    "print(\"IsActiveMember converted to binary (Yes → 1, No → 0)\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Verifying conversion successful\n",
    "print(\"\\nVerification:\")\n",
    "print(f\"HasCrCard - Type: {df['HasCrCard'].dtype}, Values: {df['HasCrCard'].unique()}\")\n",
    "print(f\"IsActiveMember - Type: {df['IsActiveMember'].dtype}, Values: {df['IsActiveMember'].unique()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2037d9f-0c8f-41c8-b846-0c64555823c6",
   "metadata": {},
   "source": [
    "### 2.5 Standardizing Geography Values\n",
    "\n",
    "**Issue:** Geography column has inconsistent country formats:\n",
    "- \"FRA\", \"France\", \"French\" all represent France\n",
    "- This creates problems for grouping and analysis\n",
    "\n",
    "**Strategy:**\n",
    "1. Check all unique values in Geography\n",
    "2. Create a mapping to standardize country names\n",
    "3. Use consistent format: \"France\", \"Germany\", \"Spain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78139a96-e17a-432a-bee4-b5c7be92b55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geography values standardized\n",
      "======================================================================\n",
      "\n",
      "After standardization:\n",
      "Geography\n",
      "France     5014\n",
      "Germany    2508\n",
      "Spain      2476\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create mapping to standardize country names\n",
    "# FRA, France, French → France\n",
    "geography_mapping = {\n",
    "    'FRA': 'France',\n",
    "    'France': 'France',\n",
    "    'French': 'France',\n",
    "    'Spain': 'Spain',\n",
    "    'Germany': 'Germany'\n",
    "}\n",
    "\n",
    "# Applying standardization\n",
    "df['Geography'] = df['Geography'].map(geography_mapping)\n",
    "\n",
    "print(\"Geography values standardized\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Showing standardized values\n",
    "print(\"\\nAfter standardization:\")\n",
    "print(df['Geography'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa10f1c3-362f-4cd8-b635-245c2b0b2532",
   "metadata": {},
   "source": [
    "### 2.6 Final Verification of Data Pre-processing\n",
    "\n",
    "Let's verify all cleaning tasks were completed successfully and the dataset is ready for exploratory analysis.\n",
    "\n",
    "**Verification Checklist:**\n",
    "- Missing values handled\n",
    "- Duplicate columns removed\n",
    "- All columns have correct data types\n",
    "- Binary columns properly encoded\n",
    "- Geography values standardized\n",
    "- Dataset ready for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "997f5173-f4d6-4756-baf0-b8e2a05c4687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL DATA QUALITY CHECK\n",
      "\n",
      "1. Dataset Dimensions:\n",
      "   Rows: 9,998\n",
      "   Columns: 13\n",
      "\n",
      "2. Missing Values:\n",
      "   Total missing values: 0\n",
      "No missing values - dataset is complete\n",
      "\n",
      "3. Data Types Summary:\n",
      "   Numeric columns: 10\n",
      "   Categorical columns: 3\n",
      "\n",
      "4. Column Data Types:\n",
      "   CustomerId          : int64     \n",
      "   Surname             : object    \n",
      "   CreditScore         : int64     \n",
      "   Geography           : object    \n",
      "   Gender              : object    \n",
      "   Age                 : float64   \n",
      "   Tenure              : int64     \n",
      "   Balance             : float64   \n",
      "   NumOfProducts       : int64     \n",
      "   HasCrCard           : int64     \n",
      "   IsActiveMember      : int64     \n",
      "   EstimatedSalary     : float64   \n",
      "   Exited              : int64     \n",
      "\n",
      "5. Categorical Column Values:\n",
      "   Geography: ['France', 'Germany', 'Spain']\n",
      "   Gender: ['Female', 'Male']\n",
      "\n",
      "6. Binary Columns:\n",
      "   HasCrCard values: [np.int64(0), np.int64(1)]\n",
      "   IsActiveMember values: [np.int64(0), np.int64(1)]\n",
      "   Exited values: [np.int64(0), np.int64(1)]\n",
      "DATA PRE-PROCESSING COMPLETE\n"
     ]
    }
   ],
   "source": [
    "print(\"FINAL DATA QUALITY CHECK\")\n",
    "\n",
    "# 1. Dataset dimensions\n",
    "print(\"\\n1. Dataset Dimensions:\")\n",
    "print(f\"   Rows: {len(df):,}\")\n",
    "print(f\"   Columns: {len(df.columns)}\")\n",
    "\n",
    "# 2. Missing values check\n",
    "print(\"\\n2. Missing Values:\")\n",
    "total_missing = df.isnull().sum().sum()\n",
    "print(f\"   Total missing values: {total_missing}\")\n",
    "if total_missing == 0:\n",
    "    print(\"No missing values - dataset is complete\")\n",
    "\n",
    "# 3. Data types verification\n",
    "print(\"\\n3. Data Types Summary:\")\n",
    "print(f\"   Numeric columns: {df.select_dtypes(include=['float64', 'int64']).shape[1]}\")\n",
    "print(f\"   Categorical columns: {df.select_dtypes(include=['object']).shape[1]}\")\n",
    "\n",
    "print(\"\\n4. Column Data Types:\")\n",
    "for col in df.columns:\n",
    "    print(f\"   {col:20s}: {str(df[col].dtype):10s}\")\n",
    "\n",
    "# 5. Categorical values check\n",
    "print(\"\\n5. Categorical Column Values:\")\n",
    "print(f\"   Geography: {sorted(df['Geography'].unique())}\")\n",
    "print(f\"   Gender: {sorted(df['Gender'].unique())}\")\n",
    "\n",
    "# 6. Binary columns verification\n",
    "print(\"\\n6. Binary Columns:\")\n",
    "print(f\"   HasCrCard values: {sorted(df['HasCrCard'].unique())}\")\n",
    "print(f\"   IsActiveMember values: {sorted(df['IsActiveMember'].unique())}\")\n",
    "print(f\"   Exited values: {sorted(df['Exited'].unique())}\")\n",
    "\n",
    "\n",
    "print(\"DATA PRE-PROCESSING COMPLETE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831584b3-cd4d-41fd-bc4c-5e7fe88533f4",
   "metadata": {},
   "source": [
    "## 2.7 Exporting Cleaned Dataset\n",
    "\n",
    "The preprocessed dataset is now ready for analysis. We'll export it as a CSV file for use in the next notebook (Exploratory Data Analysis).\n",
    "\n",
    "**Export Details:**\n",
    "- **Format:** CSV (comma-separated values)\n",
    "- **Filename:** Bank_Churn_Cleaned.csv\n",
    "- **Location:** C:\\Users\\HP USER\\Documents\\Banking-Customer-Churn-Analysis\\data\n",
    "- **Records:** 9,998 customers\n",
    "- **Columns:** 13 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f6ddf40-8363-4c7a-94a9-1dcc62be4e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dataset exported successfully!\n",
      "  Location: C:/Users/HP USER/Documents/Banking-Customer-Churn-Analysis/data/Bank_Churn_Cleaned.csv\n",
      "  Rows: 9,998\n",
      "  Columns: 13\n"
     ]
    }
   ],
   "source": [
    "# EXPORTING CLEANED DATASET\n",
    "\n",
    "# Define export path\n",
    "export_path = 'C:/Users/HP USER/Documents/Banking-Customer-Churn-Analysis/data/Bank_Churn_Cleaned.csv'\n",
    "\n",
    "df.to_csv(export_path, index=False)    # Export to CSV\n",
    "\n",
    "print(f\"  Dataset exported successfully!\")\n",
    "print(f\"  Location: {export_path}\")\n",
    "print(f\"  Rows: {len(df):,}\")\n",
    "print(f\"  Columns: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086477d1-b8fe-492e-b151-a902379134c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
